{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Captcha Recognition Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\luizf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\luizf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.26.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\luizf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset, random_split\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import math\n",
    "import random # sampling captcha text\n",
    "import os # used for path and image storage\n",
    "from captcha.image import ImageCaptcha  # Module that will generate all captcha images# pip install captcha\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device to point to a GPU if we have one, CPU otherwise.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(image_path, save_path):\n",
    "    # Open the image using Pillow\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = image.convert('L')\n",
    "\n",
    "    # Convert PIL image to numpy array\n",
    "    np_image = np.array(gray_image)\n",
    "\n",
    "    # Apply binary thresholding\n",
    "    _, binary_image = cv2.threshold(np_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Apply morphological operations\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel, iterations=1)  # Increase iterations for more noise removal\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    denoised_image = cv2.GaussianBlur(opening, (3, 3), 0)\n",
    "\n",
    "    # Apply median blur to further reduce noise, particularly small circles\n",
    "    denoised_image = cv2.medianBlur(denoised_image, 3)\n",
    "\n",
    "    # Save the denoised image\n",
    "    denoised_image_pil = Image.fromarray(denoised_image)\n",
    "    denoised_image_pil.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to resize the image\n",
    "def resize_image(image, new_width, new_height):\n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(image, (new_width, new_height))\n",
    "    return resized_image\n",
    "\n",
    "def save_contours_as_images(image_path, output_directory, image_id):\n",
    "    # Load the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Threshold the image to obtain binary image\n",
    "    _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours based on x-coordinate\n",
    "    contours = sorted(contours, key=lambda contour: cv2.boundingRect(contour)[0])\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    counter = 0 # keep track of how many characters have been saved\n",
    "    label = image_path.split('/')[0].split('.')[0].split(\"\\\\\")[1]\n",
    "    print(label)\n",
    "    image_name = label.split(\"--\")[0]\n",
    "    char_labels = [char_label for char_label in label.split(\"_\")[0]]\n",
    "    # print(char_labels)\n",
    "\n",
    "    for i, contour in enumerate(contours):\n",
    "        # Get bounding box for each contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        if counter > 3:\n",
    "            break\n",
    "\n",
    "        # Check if contour is too small (possibly noise)\n",
    "        if w > 5 and h > 5:\n",
    "            # Add some padding around the character bounding box\n",
    "            padding = 10\n",
    "            x_padding = max(0, x - padding)\n",
    "            y_padding = max(0, y - padding)\n",
    "            w_padding = min(image.shape[1], w + 2 * padding)\n",
    "            h_padding = min(image.shape[0], h + 2 * padding)\n",
    "\n",
    "            # Create a black canvas with padded dimensions\n",
    "            padded_image = np.zeros((h_padding, w_padding), dtype=np.uint8)\n",
    "\n",
    "            # Calculate coordinates to place the character in the center\n",
    "            x_offset = (w_padding - w) // 2\n",
    "            y_offset = (h_padding - h) // 2\n",
    "\n",
    "            # Copy the character region from the original image to padded image\n",
    "            padded_image[y_offset:y_offset+h, x_offset:x_offset+w] = image[y:y+h, x:x+w]\n",
    "\n",
    "            # Resize the padded image\n",
    "            resized_image = resize_image(padded_image, 100, 100)\n",
    "\n",
    "            # Save the resized image as a separate image\n",
    "            character_filename = os.path.join(output_directory, f'{image_name}_{char_labels[counter]}--{image_id}.png')\n",
    "            cv2.imwrite(character_filename, resized_image)\n",
    "            # print(f\"contour saved: {character_filename}\")\n",
    "            counter += 1\n",
    "            image_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing images to the filter (new image generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate denoised images\n",
    "folder = 'four_cap_36'\n",
    "output_folder = 'denoised_images'\n",
    "\n",
    "# Get list of all files in the folder\n",
    "file_list = os.listdir(folder)\n",
    "\n",
    "# Iterate through the first 10 images in the folder\n",
    "for i, filename in enumerate(file_list):    \n",
    "    # Check if the file is an image (you can add more image extensions if needed)\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Construct the full path to the image\n",
    "        image_path = os.path.join(folder, filename)\n",
    "        \n",
    "        # Save path for the denoised image\n",
    "        # original image -> denoised image (now named after its label)\n",
    "        label = filename.split('-')[0]\n",
    "        save_filename = f'{label}_{i}--denoised.png' # There is a possibility that the images might have the same label -- TODO: FIX IT later\n",
    "        save_path = os.path.join(output_folder, save_filename)\n",
    "        \n",
    "        # Call the remove_noise function\n",
    "        remove_noise(image_path, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping Characters (New Image Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path containing the images\n",
    "folder_path = 'denoised_images'\n",
    "\n",
    "# Output directory for saved contour images\n",
    "output_directory = 'cropped_characters'\n",
    "\n",
    "# Get list of all files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "image_id = 0\n",
    "\n",
    "# Iterate through the first 10 images in the folder\n",
    "for i, filename in enumerate(file_list):\n",
    "    # Check if the file is an image (you can add more image extensions if needed)\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Construct the full path to the image\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Call the save_contours_as_images function\n",
    "        save_contours_as_images(image_path, output_directory, image_id)\n",
    "\n",
    "        image_id += 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Class for Cropped Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CroppedCharacterDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(root_dir, img) for img in os.listdir(root_dir) if img.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')  # Convert image to grayscale\n",
    "        \n",
    "        # Extract label and image id from file name\n",
    "        filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "        # format: {ParentImageName}_{image_num}_{char_label}--{id}.png\n",
    "        parts = filename.split('_')\n",
    "        label, image_id = parts[-1].split('--')  # Split last part\n",
    "        label = label.strip()  # Remove any leading/trailing whitespace\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory where images are stored\n",
    "root_dir = \"cropped_characters\"\n",
    "\n",
    "# Define transformations if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create dataset instance\n",
    "cropped_chars_dataset = CroppedCharacterDataset(root_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7683\n",
      "Train: 7683 examples into 241 batches\n"
     ]
    }
   ],
   "source": [
    "# Define the sizes of each split\n",
    "print(len(cropped_chars_dataset)) # total number of images in dataset\n",
    "train_size = int(1 * len(cropped_chars_dataset))\n",
    "# dev_size = int(0.2 * len(cropped_chars_dataset))\n",
    "# test_size = len(cropped_chars_dataset) - train_size - dev_size\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "# train_data, dev_data, test_data = random_split(cropped_chars_dataset, [train_size, dev_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cropped_chars_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create data loaders\n",
    "# train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "# dev_loader = DataLoader(dev_data, batch_size=32, shuffle=False)\n",
    "# test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_loader.dataset)} examples into {len(train_loader)} batches\")\n",
    "# print(f\"Test: {len(test_loader.dataset)} examples into {len(test_loader)} batches\")\n",
    "# print(f\"Test: {len(dev_loader.dataset)} examples into {len(dev_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `train_model(model, dataloader, epochs)`\n",
    "\n",
    "This function should train the given model using the given data for the given number of epochs.\n",
    "\n",
    "**Arguments**\n",
    " * `model`: A PyTorch model.  You can assume here that it has already been moved to `device` (and you should assure that is the case when calling this function).\n",
    " * `dataloader`: A PyTorch DataLoader.\n",
    " * `epochs`: The number of full epochs to train.\n",
    "\n",
    "**Return value**\n",
    " * None.\n",
    "\n",
    "Use `torch.nn.CrossEntropyLoss()` for the loss function and `optim.Adam` with its default hyperparameters for the optimization algorithm.\n",
    "\n",
    "Use the `stats` object to print training statistics before, during, and after the training run (see above for instructions).\n",
    "\n",
    "Don't forget to move all tensors to `device` so they are placed on the GPU if one is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    # Starting stats object\n",
    "    # stats.start()\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Loop over the dataset for the given number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        # Iterate over the batches of data\n",
    "        for inputs, labels in dataloader:\n",
    "            # Move inputs and labels to GPU if possible\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get outputs from forward propagation\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform a single optimization step (parameter update)\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=35):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        # self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        # self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        # self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(128 * 12 * 12, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.bn1(nn.functional.relu(self.conv1(x))))\n",
    "        x = self.pool(self.bn2(nn.functional.relu(self.conv2(x))))\n",
    "        x = self.pool(self.bn3(nn.functional.relu(self.conv3(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 128 * 12 * 12)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs, learning_rate):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            # images, labels = batch[0], batch[1]  # Unpack the batch tuple and move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            # Extract and convert labels to integers\n",
    "            label_strings = [label_tuple[0] for label_tuple in labels]\n",
    "            label_indices = [label_strings.index(label) for label in label_strings]\n",
    "            labels = torch.tensor(label_indices, dtype=torch.long).to(device)\n",
    "            \n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward propagation\n",
    "            outputs = model(images)\n",
    "\n",
    "            # computer loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # backward prop\n",
    "            loss.backward()\n",
    "\n",
    "            # update\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculating stats\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = correct / total\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {100 * train_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Train Loss: 5.3861, Train Accuracy: 5.73%\n",
      "Epoch [2/5], Train Loss: 3.3821, Train Accuracy: 6.00%\n",
      "Epoch [3/5], Train Loss: 3.3835, Train Accuracy: 5.64%\n",
      "Epoch [4/5], Train Loss: 3.3730, Train Accuracy: 5.84%\n",
      "Epoch [5/5], Train Loss: 3.3732, Train Accuracy: 5.81%\n"
     ]
    }
   ],
   "source": [
    "# Get ResNet18 model with randomized weights\n",
    "model = CNNModel()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Move the model to GPU if not already in there\n",
    "train_model(model, train_loader, epochs, learning_rate)\n",
    "\n",
    "# Check accuacy without training\n",
    "# overall_accuracy, class_accuracy = test_model(model, test_loader)\n",
    "# print(f'Accuracy before training: {overall_accuracy}')\n",
    "# \n",
    "# # Train the model for 3 epochs\n",
    "# train_model(model, train_loader, 5)\n",
    "# \n",
    "# # Checki accuracy after training\n",
    "# accuracy_after_training, class_accuracies_after_training = test_model(model, test_loader)\n",
    "# print(f'Accuracy after training: {accuracy_after_training}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
