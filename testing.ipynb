{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\luizf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\luizf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.26.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\luizf\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset, random_split\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import math\n",
    "import random # sampling captcha text\n",
    "import os # used for path and image storage\n",
    "from captcha.image import ImageCaptcha  # Module that will generate all captcha images# pip install captcha\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device to point to a GPU if we have one, CPU otherwise.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(image_path, save_path):\n",
    "    # Open the image using Pillow\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = image.convert('L')\n",
    "\n",
    "    # Convert PIL image to numpy array\n",
    "    np_image = np.array(gray_image)\n",
    "\n",
    "    # Apply binary thresholding\n",
    "    _, binary_image = cv2.threshold(np_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Apply morphological operations\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel, iterations=1)  # Increase iterations for more noise removal\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    denoised_image = cv2.GaussianBlur(opening, (3, 3), 0)\n",
    "\n",
    "    # Apply median blur to further reduce noise, particularly small circles\n",
    "    denoised_image = cv2.medianBlur(denoised_image, 3)\n",
    "\n",
    "    # Save the denoised image\n",
    "    denoised_image_pil = Image.fromarray(denoised_image)\n",
    "    denoised_image_pil.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to resize the image\n",
    "def resize_image(image, new_width, new_height):\n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(image, (new_width, new_height))\n",
    "    return resized_image\n",
    "\n",
    "def save_contours_as_images(image_path, output_directory, image_id):\n",
    "    # Load the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Threshold the image to obtain binary image\n",
    "    _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours based on x-coordinate\n",
    "    contours = sorted(contours, key=lambda contour: cv2.boundingRect(contour)[0])\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    counter = 0 # keep track of how many characters have been saved\n",
    "    label = image_path.split('/')[0].split('.')[0].split(\"\\\\\")[1]\n",
    "    print(label)\n",
    "    image_name = label.split(\"--\")[0]\n",
    "    char_labels = [char_label for char_label in label.split(\"_\")[0]]\n",
    "    # print(char_labels)\n",
    "\n",
    "    for i, contour in enumerate(contours):\n",
    "        # Get bounding box for each contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        if counter > 3:\n",
    "            break\n",
    "\n",
    "        # Check if contour is too small (possibly noise)\n",
    "        if w > 5 and h > 5:\n",
    "            # Add some padding around the character bounding box\n",
    "            padding = 10\n",
    "            x_padding = max(0, x - padding)\n",
    "            y_padding = max(0, y - padding)\n",
    "            w_padding = min(image.shape[1], w + 2 * padding)\n",
    "            h_padding = min(image.shape[0], h + 2 * padding)\n",
    "\n",
    "            # Create a black canvas with padded dimensions\n",
    "            padded_image = np.zeros((h_padding, w_padding), dtype=np.uint8)\n",
    "\n",
    "            # Calculate coordinates to place the character in the center\n",
    "            x_offset = (w_padding - w) // 2\n",
    "            y_offset = (h_padding - h) // 2\n",
    "\n",
    "            # Copy the character region from the original image to padded image\n",
    "            padded_image[y_offset:y_offset+h, x_offset:x_offset+w] = image[y:y+h, x:x+w]\n",
    "\n",
    "            # Resize the padded image\n",
    "            resized_image = resize_image(padded_image, 100, 100)\n",
    "\n",
    "            # Save the resized image as a separate image\n",
    "            character_filename = os.path.join(output_directory, f'{image_name}_{char_labels[counter]}--{image_id}.png')\n",
    "            cv2.imwrite(character_filename, resized_image)\n",
    "            # print(f\"contour saved: {character_filename}\")\n",
    "            counter += 1\n",
    "            image_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing images to the filter (new image generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate denoised images\n",
    "folder = 'four_cap_36'\n",
    "output_folder = 'denoised_images'\n",
    "\n",
    "# Get list of all files in the folder\n",
    "file_list = os.listdir(folder)\n",
    "\n",
    "# Iterate through the first 10 images in the folder\n",
    "for i, filename in enumerate(file_list):    \n",
    "    # Check if the file is an image (you can add more image extensions if needed)\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Construct the full path to the image\n",
    "        image_path = os.path.join(folder, filename)\n",
    "        \n",
    "        # Save path for the denoised image\n",
    "        # original image -> denoised image (now named after its label)\n",
    "        label = filename.split('-')[0]\n",
    "        save_filename = f'{label}_{i}--denoised.png' # There is a possibility that the images might have the same label -- TODO: FIX IT later\n",
    "        save_path = os.path.join(output_folder, save_filename)\n",
    "        \n",
    "        # Call the remove_noise function\n",
    "        remove_noise(image_path, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping characters (new image generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path containing the images\n",
    "folder_path = 'denoised_images'\n",
    "\n",
    "# Output directory for saved contour images\n",
    "output_directory = 'cropped_characters'\n",
    "\n",
    "# Get list of all files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "image_id = 0\n",
    "\n",
    "# Iterate through the first 10 images in the folder\n",
    "for i, filename in enumerate(file_list):\n",
    "    # Check if the file is an image (you can add more image extensions if needed)\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        # Construct the full path to the image\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Call the save_contours_as_images function\n",
    "        save_contours_as_images(image_path, output_directory, image_id)\n",
    "\n",
    "        image_id += 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Class for characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CroppedCharacterDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(root_dir, img) for img in os.listdir(root_dir) if img.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('L')  # Convert image to grayscale\n",
    "        \n",
    "        # Extract label and image id from file name\n",
    "        filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "        # format: {ParentImageName}_{image_num}_{char_label}--{id}.png\n",
    "        parts = filename.split('_')\n",
    "        label, image_id = parts[-1].split('--')  # Split last part\n",
    "        label = label.strip()  # Remove any leading/trailing whitespace\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory where images are stored\n",
    "root_dir = \"cropped_characters\"\n",
    "\n",
    "# Define transformations if needed\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create dataset instance\n",
    "cropped_chars_dataset = CroppedCharacterDataset(root_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7683\n",
      "Train: 4609 examples into 145 batches\n",
      "Test: 1538 examples into 49 batches\n",
      "Test: 1536 examples into 48 batches\n"
     ]
    }
   ],
   "source": [
    "# Define the sizes of each split\n",
    "print(len(cropped_chars_dataset)) # total number of images in dataset\n",
    "train_size = int(0.6 * len(cropped_chars_dataset))\n",
    "dev_size = int(0.2 * len(cropped_chars_dataset))\n",
    "test_size = len(cropped_chars_dataset) - train_size - dev_size\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "train_data, dev_data, test_data = random_split(cropped_chars_dataset, [train_size, dev_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "dev_loader = DataLoader(dev_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_loader.dataset)} examples into {len(train_loader)} batches\")\n",
    "print(f\"Test: {len(test_loader.dataset)} examples into {len(test_loader)} batches\")\n",
    "print(f\"Test: {len(dev_loader.dataset)} examples into {len(dev_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important functions for next steps\n",
    "\n",
    "Credits: Mark Liffiton; CS387 Spring 2024 Assignment 5\n",
    "\n",
    "### `test_model(model, dataloader)`\n",
    "\n",
    "This function calculates accuracy statistics for a given model on given data.\n",
    "\n",
    "**Arguments**\n",
    " * `model`: A PyTorch model.  It should have already been moved to `device` (and you should assure that is the case when calling this function).\n",
    " * `dataloader`: A PyTorch DataLoader.\n",
    "\n",
    "**Return value**\n",
    " * A tuple of two values:\n",
    "    1. Overall accuracy of the given model on the given data.\n",
    "    2. A dictionary mapping class names for the given dataset to accuracies for the model's predictions of examples within each class.\n",
    "\n",
    "To call it and print the accuracies it returns, you can use code like this:\n",
    "```python\n",
    "acc, class_acc = test_model(model, testloader)\n",
    "print(f\"Accuracy: {acc:.4f}   Class accuracies: {class_acc}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader):\n",
    "    classes = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'] # here are all the possible classes present in the data (sorted).\n",
    "    class_correct = {clsname: 0 for clsname in classes}\n",
    "    class_total = {clsname: 0 for clsname in classes}\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    counter = 0\n",
    "    for data in dataloader:\n",
    "        if counter >= 1:\n",
    "            break\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = [x for x in data]\n",
    "\n",
    "        print(inputs)\n",
    "        print(labels)\n",
    "        counter += 1\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     for data in dataloader:\n",
    "    #         # get the inputs; data is a list of [inputs, labels]\n",
    "    #         inputs, labels = [x.to(device) for x in data]\n",
    "\n",
    "    #         # forward\n",
    "    #         outputs = model(inputs)\n",
    "\n",
    "    #         # get predictions from multiple class outputs\n",
    "    #         _, predicted = torch.max(outputs, 1)\n",
    "    #         # find and count the correct predictions\n",
    "    #         corrects = (predicted == labels).squeeze()\n",
    "    #         total_correct += corrects.sum()\n",
    "    #         total += outputs.shape[0]\n",
    " \n",
    "    #         # count correct predictions within each clsas\n",
    "    #         for label, correct in zip(labels, corrects):\n",
    "    #             clsname = classes[label]\n",
    "    #             class_correct[clsname] += correct.item()\n",
    "    #             class_total[clsname] += 1\n",
    " \n",
    "    # # compute overall accuracies\n",
    "    # accuracy = (total_correct / total).item()\n",
    "    # class_accuracies = {clsname: class_correct[clsname]/class_total[clsname]\n",
    "    #                     for clsname in classes}\n",
    " \n",
    "    # return accuracy, class_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `StatReporter` Class\n",
    "\n",
    "Credits: Mark Liffiton; CS387 Spring 2024 Assignment 5\n",
    "\n",
    "This class will help report training statistics as training is running.  This cell creates a single global object named `stats` that you should use in any training run.\n",
    "\n",
    "Basically, use this in `train_model()` as follows:\n",
    "1. Call `stats.start()` right when each training run begins,\n",
    "2. After each iteration of training, call `stats.iteration(epoch, i, loss)` with the current epoch number, current iteration number, and current loss value.\n",
    "3. Call `stats.end()` right when a training run concludes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatReporter:\n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "        self.elapsed = 0\n",
    "        self.target = 0\n",
    "        self.loss = None\n",
    "\n",
    "    def iteration(self, epoch, i, loss):\n",
    "        self.loss = loss\n",
    "\n",
    "        iteration_time = time.time() - self.start_time\n",
    "        self.elapsed += iteration_time\n",
    "        self.start_time = time.time()\n",
    "        if self.elapsed > self.target:\n",
    "            print(f\"Epoch {epoch+1:2d}, iteration {i+1:3d}:  Loss = {loss:.3f}  Iteration time = {iteration_time:0.3f}\")\n",
    "            self.target += 10\n",
    "\n",
    "    def end(self):\n",
    "        print(f\"Training complete.  Elapsed time: {self.elapsed:.2f} seconds  Final loss: {self.loss:0.3f}\")\n",
    "\n",
    "stats = StatReporter()  # one StatReporter object to use throughout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `train_model(model, dataloader, epochs)`\n",
    "\n",
    "This function should train the given model using the given data for the given number of epochs.\n",
    "\n",
    "**Arguments**\n",
    " * `model`: A PyTorch model.  You can assume here that it has already been moved to `device` (and you should assure that is the case when calling this function).\n",
    " * `dataloader`: A PyTorch DataLoader.\n",
    " * `epochs`: The number of full epochs to train.\n",
    "\n",
    "**Return value**\n",
    " * None.\n",
    "\n",
    "Use `torch.nn.CrossEntropyLoss()` for the loss function and `optim.Adam` with its default hyperparameters for the optimization algorithm.\n",
    "\n",
    "Use the `stats` object to print training statistics before, during, and after the training run (see above for instructions).\n",
    "\n",
    "Don't forget to move all tensors to `device` so they are placed on the GPU if one is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, epochs):\n",
    "    # Starting stats object\n",
    "    # stats.start()\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Loop over the dataset for the given number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        i = 0 # iteration counter for stats function call\n",
    "\n",
    "        # Iterate over the batches of data\n",
    "        for inputs, labels in dataloader:\n",
    "            # Move inputs and labels to GPU if possible\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get outputs from forward propagation\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy after each iteration\n",
    "            # stats.iteration(epoch, i, loss)\n",
    "\n",
    "            # i++\n",
    "            i += 1\n",
    "\n",
    "        # Ending stats object\n",
    "        # stats.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 25 * 25, 128)  # 64 channels after max pooling with 25x25 spatial size\n",
    "        self.fc2 = nn.Linear(128, 35) # 35 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 25 * 25)  # Flatten before fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader):\n",
    "    classes = ['1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'] # here are all the possible classes present in the data (sorted).\n",
    "    class_correct = {clsname: 0 for clsname in classes}\n",
    "    class_total = {clsname: 0 for clsname in classes}\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    counter = 0\n",
    "    for data in dataloader:\n",
    "        if counter >= 1:\n",
    "            break\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = [x for x in data]\n",
    "\n",
    "        print(len(inputs))\n",
    "        print(labels)\n",
    "        counter += 1\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     for data in dataloader:\n",
    "    #         # get the inputs; data is a list of [inputs, labels]\n",
    "    #         inputs, labels = [x.to(device) for x in data]\n",
    "\n",
    "    #         # forward\n",
    "    #         outputs = model(inputs)\n",
    "\n",
    "    #         # get predictions from multiple class outputs\n",
    "    #         _, predicted = torch.max(outputs, 1)\n",
    "    #         # find and count the correct predictions\n",
    "    #         corrects = (predicted == labels).squeeze()\n",
    "    #         total_correct += corrects.sum()\n",
    "    #         total += outputs.shape[0]\n",
    " \n",
    "    #         # count correct predictions within each clsas\n",
    "    #         for label, correct in zip(labels, corrects):\n",
    "    #             clsname = classes[label]\n",
    "    #             class_correct[clsname] += correct.item()\n",
    "    #             class_total[clsname] += 1\n",
    " \n",
    "    # # compute overall accuracies\n",
    "    # accuracy = (total_correct / total).item()\n",
    "    # class_accuracies = {clsname: class_correct[clsname]/class_total[clsname]\n",
    "    #                     for clsname in classes}\n",
    " \n",
    "    # return accuracy, class_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "('P', 'Q', '9', 'J', 'Z', 'G', 'X', '9', 'D', 'L', 'W', 'O', 'Z', 'F', 'C', 'P', '5', 'G', 'J', 'B', 'V', 'W', 'O', '2', 'D', '9', 'O', 'X', 'F', 'Z', 'F', '2')\n"
     ]
    }
   ],
   "source": [
    "# Get ResNet18 model with randomized weights\n",
    "model = CNNModel()\n",
    "\n",
    "# Move the model to GPU if not already in there\n",
    "test_model(model, train_loader)\n",
    "\n",
    "# Check accuacy without training\n",
    "# overall_accuracy, class_accuracy = test_model(model, test_loader)\n",
    "# print(f'Accuracy before training: {overall_accuracy}')\n",
    "# \n",
    "# # Train the model for 3 epochs\n",
    "# train_model(model, train_loader, 5)\n",
    "# \n",
    "# # Checki accuracy after training\n",
    "# accuracy_after_training, class_accuracies_after_training = test_model(model, test_loader)\n",
    "# print(f'Accuracy after training: {accuracy_after_training}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
