{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install os\n",
    "!pip install cv2\n",
    "!pip install glob\n",
    "!pip install shutil\n",
    "!pip install scipy\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "from noise_reduction import NoiseRemover\n",
    "from character_segmenter import CharacterSegmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of which characters we're trying to classify\n",
    "letter_set = [chr(ascii_val) for ascii_val in range(ord('A'), ord('Z') + 1)]\n",
    "number_set = [chr(ascii_val) for ascii_val in range(ord('0'), ord('9') + 1)]\n",
    "char_set = letter_set + number_set\n",
    "char_counts = {char : 0 for char in char_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(\"data\", \"characters\", \"all_chars\")):\n",
    "    shutil.rmtree(os.path.join(\"data\", \"characters\", \"all_chars\")) # clear previous data\n",
    "\n",
    "# check if 'characters' folder exists, as well as folders for each digit individually\n",
    "# characters_dataset_path = os.path.join(\"data\", \"characters\")\n",
    "# if not os.path.exists(characters_dataset_path):\n",
    "#     os.mkdir(characters_dataset_path)\n",
    "# characters_dataset_split_path = os.path.join(\"data\", \"characters\", \"all_chars\")\n",
    "# if not os.path.exists(characters_dataset_split_path):\n",
    "#     os.mkdir(characters_dataset_split_path)\n",
    "# for char in char_set:\n",
    "#     char_folder_path = os.path.join(\"data\", \"characters\", \"all_chars\", char)\n",
    "#     if not os.path.exists(char_folder_path):\n",
    "#         os.mkdir(char_folder_path)\n",
    "\n",
    "# loop over all the CAPTCHA images\n",
    "captchas_path = os.path.join(\"data\", \"captchas\", \"*.jpg\") # path to all CAPTCHAs\n",
    "captcha_paths = glob.glob(captchas_path) # all paths to individual CAPTCHAs\n",
    "num_bad_captchas = 0\n",
    "for captcha_index, captcha_path in enumerate(captcha_paths):\n",
    "    # image meta-details\n",
    "    img_fn = os.path.split(captcha_path)[1] # convert from \"data/captchas/1ZX0.jpg\" to \"1ZX0.jpg\"\n",
    "    captcha_label = img_fn.split(\".\")[0] # convert from \"1ZX0.jpg\" to \"1ZX0\"\n",
    "\n",
    "    # read in image and perform preliminary thresholding to prepare for denoising\n",
    "    img = cv2.imread(captcha_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, img = cv2.threshold(img, 230, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # clean up the image by removing noise\n",
    "    clean_image = NoiseRemover.remove_all_noise(img)\n",
    "\n",
    "    masks, mask_sizes, mask_start_indices, mask_char_pixels_arrs = CharacterSegmenter.get_components(clean_image)\n",
    "    if len(masks) == 0:\n",
    "        num_bad_captchas += 1\n",
    "        continue\n",
    "\n",
    "    # segment and extract characters\n",
    "    masks, mask_start_indices = CharacterSegmenter.segment_characters(masks, mask_sizes, mask_start_indices, mask_char_pixels_arrs)\n",
    "    if not len(masks) == 4:\n",
    "        num_bad_captchas += 1\n",
    "        continue\n",
    "\n",
    "    # reorder masks and starting indices in ascending order to align them with the proper character for labeling\n",
    "    mask_start_indices, indices = zip(*sorted(zip(mask_start_indices, [i for i in range(len(mask_start_indices))]))) # make sure intervals are in left-to-right order so we can segment characters properly\n",
    "    masks = [masks[i] for i in indices]\n",
    "    char_infos = [(masks[i], captcha_label[i]) for i in range(len(masks))]\n",
    "\n",
    "    # save characters to disk\n",
    "    for index, char_info in enumerate(char_infos):\n",
    "        char_crop, label = char_info\n",
    "\n",
    "        # reshape character crop to 76x76\n",
    "        char_crop = CharacterSegmenter.squarify_image(char_crop)\n",
    "        char_crop = ~char_crop\n",
    "\n",
    "        # save digit to file so we can train a CNN later\n",
    "        char_save_path = os.path.join(\"data\", \"characters\", \"all_chars\", label, \"{}_{}.jpg\".format(label, char_counts[label]))\n",
    "        cv2.imwrite(char_save_path, char_crop)\n",
    "        char_counts[label] += 1\n",
    "\n",
    "    if captcha_index % 100 == 0:\n",
    "        print(\"Processed {}/{} ({}%) CAPTCHAs...\".format(captcha_index + 1, len(captcha_paths), round((captcha_index+1) / len(captcha_paths) * 100.0, 2)))\n",
    "print(\"Number of bad CAPTCHAs: {}/{} ({}%)\".format(num_bad_captchas, len(captcha_paths), num_bad_captchas / len(captcha_paths) * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_noise_captcha(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    thresholded = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\n",
    "\n",
    "    # Apply morphological operations (closing) to further remove noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    closed = cv2.morphologyEx(thresholded, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '__array_interface__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(four_cap_36_dataset))\n\u001b[0;32m      6\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m image, label \u001b[38;5;241m=\u001b[39m \u001b[43mfour_cap_36_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, image)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel:\u001b[39m\u001b[38;5;124m\"\u001b[39m, label)\n",
      "File \u001b[1;32mc:\\Users\\luizf\\OneDrive\\Documentos\\GitHub-Reps\\CS387-Captcha-Recognition\\dataset.py:66\u001b[0m, in \u001b[0;36mCustomImageDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     62\u001b[0m image \u001b[38;5;241m=\u001b[39m read_image(img_path) \u001b[38;5;66;03m# reads image from image path\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Assuming img_tensor is your image tensor\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Convert the tensor to a PIL Image\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m image_pil \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# image = torch.Tensor(image)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image_pil, label\n",
      "File \u001b[1;32mc:\\Users\\luizf\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3087\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromarray\u001b[39m(obj, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3041\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3042\u001b[0m \u001b[38;5;124;03m    Creates an image memory from an object exporting the array interface\u001b[39;00m\n\u001b[0;32m   3043\u001b[0m \u001b[38;5;124;03m    (using the buffer protocol)::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.1.6\u001b[39;00m\n\u001b[0;32m   3086\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3087\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array_interface__\u001b[49m\n\u001b[0;32m   3088\u001b[0m     shape \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3089\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '__array_interface__'"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "\n",
    "four_cap_36_dataset = dataset.CustomImageDataset(\"four_cap_36.txt\", \"four_cap_36\")\n",
    "\n",
    "print(len(four_cap_36_dataset))\n",
    "idx = 0\n",
    "image, label = four_cap_36_dataset[idx]\n",
    "print(\"Image shape:\", image)\n",
    "print(\"Label:\", label)\n",
    "\n",
    "# Reduce noise in the image\n",
    "# img_processed = remove_all_noise(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
