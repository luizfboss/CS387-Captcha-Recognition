{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cv2\n",
    "!pip install pytesseract\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import math\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(image_path, save_path):\n",
    "    # Open the image using Pillow\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = image.convert('L')\n",
    "\n",
    "    # Convert PIL image to numpy array\n",
    "    np_image = np.array(gray_image)\n",
    "\n",
    "    # Apply binary thresholding\n",
    "    _, binary_image = cv2.threshold(np_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Apply morphological operations\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    denoised_image = cv2.GaussianBlur(opening, (3, 3), 0)\n",
    "\n",
    "    # Save the denoised image\n",
    "    denoised_image_pil = Image.fromarray(denoised_image)\n",
    "    denoised_image_pil.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder = 'easy_dataset'\n",
    "image_file = '2b827.png'\n",
    "path = os.path.join(folder, image_file)\n",
    "remove_noise(path, 'denoised_captcha.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseRemover():\n",
    "    def _erase_circles(img, circles):\n",
    "        circles = circles[0] # hough circles returns a nested list for some reason\n",
    "        for circle in circles:\n",
    "            x = circle[0] # x coordinate of circle's center\n",
    "            y = circle[1] # y coordinate of circle's center\n",
    "            r = circle[2] # radius of circle\n",
    "            img = cv2.circle(img, center = (x, y), radius = r, color = (255), thickness = 2) # erase circle by making it white (to match the image background)\n",
    "        return img\n",
    "\n",
    "    def _detect_and_remove_circles(img):\n",
    "        hough_circle_locations = cv2.HoughCircles(img, method = cv2.HOUGH_GRADIENT, dp = 1, minDist = 1, param1 = 50, param2 = 5, minRadius = 0, maxRadius = 2)\n",
    "        if hough_circle_locations is not None:\n",
    "            img = NoiseRemover._erase_circles(img, hough_circle_locations)\n",
    "        return img\n",
    "\n",
    "    def remove_all_noise(img):\n",
    "        # run some basic tests to get rid of easy-to-remove noise -- first pass\n",
    "        img = ~img # white letters, black background\n",
    "        img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations = 1) # weaken circle noise and line noise\n",
    "        img = ~img # black letters, white background\n",
    "        img = scipy.ndimage.median_filter(img, (5, 1)) # remove line noise\n",
    "        img = scipy.ndimage.median_filter(img, (1, 3)) # weaken circle noise\n",
    "        img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations = 1) # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
    "        img = scipy.ndimage.median_filter(img, (3, 3)) # remove any final 'weak' noise that might be present (line or circle)\n",
    "\n",
    "        # detect any remaining circle noise\n",
    "        img = NoiseRemover._detect_and_remove_circles(img) # after dilation, if concrete circles exist, use hough transform to remove them\n",
    "\n",
    "        # eradicate any final noise that wasn't removed previously -- second pass\n",
    "        img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations = 1) # actually performs erosion\n",
    "        img = scipy.ndimage.median_filter(img, (5, 1)) # finally completely remove any extra noise that remains\n",
    "        img = cv2.erode(img, np.ones((3, 3), np.uint8), iterations = 2) # dilate image to make it look like the original\n",
    "        img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations = 1) # erode just a bit to polish fine details\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterSegmenter():\n",
    "    def find_nonzero_intervals(vec):\n",
    "        zero_elements = (vec == 0) * 1 # mark zero-elements as 1 and non-zero elements as 0\n",
    "        nonzero_borders = np.diff(zero_elements) # find diff between each element and its neighbor (-1 and 1 represent borders, 0 represents segment or non-segment element)\n",
    "        edges, = np.nonzero(nonzero_borders) # NOTE: comma is vital to extract first element from tuple\n",
    "        edge_vec = [edges+1] # helps maintain zero-indexing properties (not important to discuss)\n",
    "        if vec[0] != 0: # special case: catch a segment that starts at the beginning of the array without a 0 border\n",
    "            edge_vec.insert(0, [0]) # index 0 goes at the beginning of the list to remain proper spatial ordering of intervals\n",
    "        if vec[-1] != 0: # special case: catch a segment that ends at the end of the array without a 0 border\n",
    "            edge_vec.append([len(vec)]) # goes at the end of the list to remain proper spatial ordering of intervals\n",
    "        edges = np.concatenate(edge_vec) # generate final edge list containing indices of 0 elements bordering non-zero segments\n",
    "        interval_pairs = [(edges[i], edges[i+1]) for i in range(0, len(edges)-1, 2)] # pair up start and end indices\n",
    "        interval_lengths = [pair[1] - pair[0] for pair in interval_pairs]\n",
    "        return interval_pairs, interval_lengths\n",
    "\n",
    "    def squarify_image(img):\n",
    "        # reshape character crop from (height x width) to (height x height) where height > width\n",
    "        img_height, img_width = img.shape\n",
    "        if img_height > img_width: # make the image fatter\n",
    "            padding = (img_height - img_width) / 2 # force crop to go from 76 x crop_width to 76 x 76 so we can train a CNN\n",
    "            img = cv2.copyMakeBorder(img, top = 0, bottom = 0, left = math.floor(padding), right = math.ceil(padding), borderType = cv2.BORDER_CONSTANT, value = 255)\n",
    "        elif img_height < img_width: # make the image skinnier\n",
    "            margin = (img_width - img_height) / 2\n",
    "            begin_column = int(0 + math.floor(margin))\n",
    "            end_column = int(img_width - math.ceil(margin))\n",
    "            img = img[:, begin_column : end_column]\n",
    "        return img\n",
    "\n",
    "    def get_components(img):\n",
    "        # find number of components\n",
    "        img = ~img\n",
    "        ret, markers_original = cv2.connectedComponents(img)\n",
    "\n",
    "        placeholder = ~img\n",
    "\n",
    "        # perform watershed segmentation\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        markers = cv2.watershed(~img, markers_original)\n",
    "\n",
    "        markers[placeholder == 255] = -1\n",
    "        unique_markers = np.unique(markers)\n",
    "\n",
    "        masks = []\n",
    "        mask_sizes = []\n",
    "        mask_start_indices = []\n",
    "        mask_char_pixels_arrs = []\n",
    "        if len(unique_markers) > 1:\n",
    "            for marker in unique_markers[1:]:\n",
    "                # extract the mask\n",
    "                mask = np.array((markers != marker) * 255, np.uint8)\n",
    "                image_height = mask.shape[0]\n",
    "                num_white_pixels = (mask.sum(axis = 0) / 255) # count number of 255-valued (white) pixels in each column\n",
    "                num_char_pixels = image_height - num_white_pixels\n",
    "                mask_start_index = np.nonzero(num_char_pixels > 0)[0][0]\n",
    "\n",
    "                # crop image to only tightly wrap around the character\n",
    "                interval, _ = CharacterSegmenter.find_nonzero_intervals(num_char_pixels)\n",
    "                start, end = interval[0]\n",
    "                mask = mask[:, start:end]\n",
    "\n",
    "                # count number of pixels corresponding to a character in the image\n",
    "                char_pixels_arr = np.count_nonzero(mask == 0, axis = 0)\n",
    "                num_black_pixels = np.sum(char_pixels_arr)\n",
    "\n",
    "                # meta information about the mask\n",
    "                masks.append(mask)\n",
    "                mask_sizes.append(num_black_pixels)\n",
    "                mask_start_indices.append(mask_start_index)\n",
    "                mask_char_pixels_arrs.append(char_pixels_arr)\n",
    "        return (masks, mask_sizes, mask_start_indices, mask_char_pixels_arrs)\n",
    "\n",
    "    def segment_characters(masks, mask_sizes, mask_start_indices, mask_char_pixel_arrs):\n",
    "        # prune out characters with too few pixels (they're just noise)\n",
    "        masks = [masks[i] for i in range(len(masks)) if mask_sizes[i] > 100]\n",
    "        mask_start_indices = [mask_start_indices[i] for i in range(len(mask_start_indices)) if mask_sizes[i] > 100]\n",
    "        mask_char_pixel_arrs = [mask_char_pixel_arrs[i] for i in range(len(mask_char_pixel_arrs)) if mask_sizes[i] > 100]\n",
    "        mask_sizes = [size for size in mask_sizes if size > 100]\n",
    "\n",
    "        iters = 0\n",
    "        while len(masks) < 4 and len(masks) > 0 and iters < 10: # while we haven't found 4 intervals representing 4 characters\n",
    "            largest_mask_index = np.argmax(mask_sizes) # index of longest interval (split up largest interval because it's the most likely one to have more than one character)\n",
    "\n",
    "            largest_mask = masks[largest_mask_index]\n",
    "            largest_mask_size = mask_sizes[largest_mask_index]\n",
    "            mask_start_index = mask_start_indices[largest_mask_index] # unwrap interval tuple\n",
    "            mask_char_pixels = mask_char_pixel_arrs[largest_mask_index]\n",
    "\n",
    "            # when splitting up an interval that might contain 2 characters, we COULD split it directly down the middle, but that's a naive approach\n",
    "            # instead, just say the best candidate column index to split the characters is the column with the fewest black pixels that's in the middle of this interval (if you include the edges, those might be labeled as the 'best candidate', when in reality they're just the beginning or end edge of a character, and not at the intersection of the two characters)\n",
    "            padding_value = 0.49 if largest_mask_size < 2200 else 0.1\n",
    "            margin_length = int(largest_mask.shape[1] * padding_value) # only consider candidates in the middle (padding_value)% of the interval (to remove noisy results on edges of characters), so remove 25% of the interval to the left and 25% of the interval to the right\n",
    "            new_interval_start = margin_length # start index in the middle (padding_value)% of this interval\n",
    "            new_interval_end = largest_mask.shape[1] - margin_length # end index in the middle (padding_value)% of this interval\n",
    "            divider_offset = np.argmin(mask_char_pixels[new_interval_start : new_interval_end]) # found the best candidate column to split the characters -- call this the offset of the character divider from the true start index of the interval\n",
    "\n",
    "            # preprocess left sub-mask\n",
    "            left_start = 0\n",
    "            left_end = new_interval_start + divider_offset\n",
    "            left_mask = largest_mask[:, left_start : left_end]\n",
    "            left_char_pixels = mask_char_pixels[left_start : left_end]\n",
    "            left_start_index = mask_start_index\n",
    "            left_mask_size = np.sum(left_char_pixels)\n",
    "\n",
    "            # preprocess right sub-mask\n",
    "            right_start = new_interval_start + divider_offset\n",
    "            right_end = largest_mask.shape[1]\n",
    "            right_mask = largest_mask[:, right_start : right_end]\n",
    "            right_char_pixels = mask_char_pixels[right_start : right_end]\n",
    "            right_start_index = mask_start_index + new_interval_start + divider_offset\n",
    "            right_mask_size = np.sum(right_char_pixels)\n",
    "\n",
    "            # replace the 'super-interval' (most likely containing two characters) in the intervals list with the two new sub-intervals\n",
    "            masks[largest_mask_index] = left_mask\n",
    "            masks.insert(largest_mask_index + 1, right_mask)\n",
    "            mask_sizes[largest_mask_index] = left_mask_size\n",
    "            mask_sizes.insert(largest_mask_index + 1, right_mask_size)\n",
    "            mask_start_indices[largest_mask_index] = left_start_index\n",
    "            mask_start_indices.insert(largest_mask_index + 1, right_start_index)\n",
    "            mask_char_pixel_arrs[largest_mask_index] = left_char_pixels\n",
    "            mask_char_pixel_arrs.insert(largest_mask_index + 1, right_char_pixels)\n",
    "\n",
    "            # prune out characters with too few pixels (they're just noise)\n",
    "            masks = [masks[i] for i in range(len(masks)) if mask_sizes[i] > 100]\n",
    "            mask_start_indices = [mask_start_indices[i] for i in range(len(mask_start_indices)) if mask_sizes[i] > 100]\n",
    "            mask_char_pixel_arrs = [mask_char_pixel_arrs[i] for i in range(len(mask_char_pixel_arrs)) if mask_sizes[i] > 100]\n",
    "            mask_sizes = [size for size in mask_sizes if size > 100]\n",
    "\n",
    "            iters += 1\n",
    "        return masks, mask_start_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_image(image_path):\n",
    "        # find image path and label indicating which characters are in the CAPTCHA\n",
    "\n",
    "        img_path = image_path # just a normal path\n",
    "        captcha_label = os.path.split(img_path)[1].split(\".\")[0] # convert from 'data/38A7.jpg' to '38A7.jpg' to '38A7'\n",
    "\n",
    "        # load the image\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        ### preprocess the image (same steps used in preprocess_dataset.py)\n",
    "        _, img = cv2.threshold(img, 230, 255, cv2.THRESH_BINARY) # binarize the image\n",
    "        clean_image = NoiseRemover.remove_all_noise(img) # clean up the image by removing noise\n",
    "\n",
    "        # find how many characters there might be to see if we need to extract additional data\n",
    "        masks, mask_sizes, mask_start_indices, mask_char_pixels_arrs = CharacterSegmenter.get_components(clean_image)\n",
    "        if len(masks) == 0:\n",
    "            return None, None\n",
    "\n",
    "        # segment and extract characters\n",
    "        masks, mask_start_indices = CharacterSegmenter.segment_characters(masks, mask_sizes, mask_start_indices, mask_char_pixels_arrs)\n",
    "        if not len(masks) == 4:\n",
    "            return None, None\n",
    "\n",
    "        # reorder masks and starting indices in ascending order to align them with the proper character for labeling\n",
    "        mask_start_indices, indices = zip(*sorted(zip(mask_start_indices, [i for i in range(len(mask_start_indices))]))) # make sure intervals are in left-to-right order so we can segment characters properly\n",
    "        masks = [masks[i] for i in indices]\n",
    "\n",
    "        # split chars and labels into two separate lists\n",
    "        chars = [masks[i] for i in range(len(masks))]\n",
    "        labels = [captcha_label[i] for i in range(len(masks))]\n",
    "\n",
    "        # reshape character crops to 76x76\n",
    "        chars = [CharacterSegmenter.squarify_image(char) for char in chars]\n",
    "        chars = [~char for char in chars]\n",
    "\n",
    "        return chars, labels\n",
    "\n",
    "image = \"denoise_testing/2.png\"\n",
    "_load_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
